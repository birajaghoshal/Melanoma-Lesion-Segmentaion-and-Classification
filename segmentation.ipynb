{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net for Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\huzai\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from skimage.transform import rescale, resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def disp(I):\n",
    "    I = np.uint8(I)\n",
    "    cv2.imshow('image', I)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to resize the dataset \n",
    "* The aspect ratio of images is preserved while resizing since the shape could be a potential feature of the segmented image.\n",
    "* The scaling factors in x and y directions are computed for each image keeping ** 384 x 384 ** as the target spatial dimensions.\n",
    "* The minimum of the scaling factors in the x and y directions is chosen as the final scaling factor.\n",
    "* By doing so at least one of the dimensions of the resized image will span the corresponding dimension of the CNN input size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resizer(input_folder_path, output_folder_path, CNN_input_size):\n",
    "    for file_name in os.listdir(input_folder_path):\n",
    "        img = cv2.imread(os.path.join(input_folder_path, file_name))\n",
    "        height, width = img.shape[:2]\n",
    "        scale_x = CNN_input_size[1] / width\n",
    "        scale_y = CNN_input_size[0] / height\n",
    "        scale_both = min(scale_x, scale_y)\n",
    "        new_width = int(scale_both * width)\n",
    "        new_height = int(scale_both * height)\n",
    "        img = cv2.resize(img, (new_width, new_height))\n",
    "        padded_img = np.zeros(CNN_input_size)\n",
    "        row_low = int((CNN_input_size[0] - new_height) / 2)\n",
    "        row_high = row_low + new_height - 1\n",
    "        col_low = int((CNN_input_size[1] - new_width) / 2)\n",
    "        col_high = col_low + new_width - 1\n",
    "        padded_img[row_low : row_high + 1, col_low : col_high + 1, :] = img\n",
    "        cv2.imwrite(os.path.join(output_folder_path, file_name), padded_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize Melonoma images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "melonoma_input_folder = '../Dataset/Images/melanoma'\n",
    "melonoma_output_folder = '../Dataset/Images/melonoma-resized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resizer(melonoma_input_folder, melonoma_output_folder, CNN_input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize Other images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "others_input_folder = '../Dataset/Images/others'\n",
    "others_output_folder = '../Dataset/Images/others-resized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resizer(others_input_folder, others_output_folder, CNN_input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize Ground-Truth images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ground_truth_input_folder = '../Dataset/Images/gt'\n",
    "ground_truth_output_folder = '../Dataset/Images/gt-resized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resizer(ground_truth_input_folder, ground_truth_output_folder, CNN_input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for file_name in os.listdir(melonoma_output_folder):\n",
    "    train_img = cv2.imread(os.path.join(melonoma_output_folder, file_name))\n",
    "    X_train.append(train_img)\n",
    "    train_label = cv2.imread(os.path.join(ground_truth_output_folder, file_name[:12] + '_segmentation.png'), 0)\n",
    "    Y_train.append(train_label)\n",
    "for file_name in os.listdir(others_output_folder):\n",
    "    train_img = cv2.imread(os.path.join(others_output_folder, file_name))\n",
    "    X_train.append(train_img)\n",
    "    train_label = cv2.imread(os.path.join(ground_truth_output_folder, file_name[:12] + '_segmentation.png'), 0)\n",
    "    Y_train.append(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 384, 384, 3)\n",
      "(2000, 384, 384, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "# Binary Thresholding to undo the blurring caused by cv2.resize()\n",
    "Y_train[Y_train >= 127] = 255\n",
    "Y_train[Y_train < 127] = 0\n",
    "Y_train = np.expand_dims(Y_train, axis = 3) / 255\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('../Dataset/Train_Data/train_segmentation', a = X_train, b = Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 384, 384, 3)\n",
      "(2000, 384, 384, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nExpected Output\\n(2000, 384, 384, 3)\\n(2000, 384, 384, 1)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('../Dataset/Train_Data/train_segmentation.npz')\n",
    "X = data['a']\n",
    "Y = data['b']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.10, random_state = 7)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "'''\n",
    "Expected Output\n",
    "(2000, 384, 384, 3)\n",
    "(2000, 384, 384, 1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CNN_input_size = [384, 384, 3]\n",
    "trained_segmenter_path = '../Trained/segmenter.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean IoU Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_IoU(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IoU Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def IoU_loss(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
    "    return 1 - intersection / union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined IoU Loss with Binary Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def IoU_loss_with_binary_crossentropy(y_true, y_pred):\n",
    "    return IoU_loss(y_true, y_pred) + tf.keras.losses.binary_crossentropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 384, 384, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 384, 384, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 384, 384, 8)  224         lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 384, 384, 8)  584         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 192, 192, 8)  0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 192, 192, 16) 1168        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 192, 192, 16) 2320        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 96, 96, 16)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 96, 96, 32)   4640        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 96, 96, 32)   9248        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 48, 48, 32)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 48, 48, 64)   18496       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 48, 48, 64)   36928       conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 24, 24, 64)   0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 24, 24, 128)  73856       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 24, 24, 128)  147584      conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 48, 48, 64)   32832       conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 48, 48, 128)  0           conv2d_transpose_5[0][0]         \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 48, 48, 64)   73792       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 48, 48, 64)   36928       conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 96, 96, 32)   8224        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 96, 96, 64)   0           conv2d_transpose_6[0][0]         \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 96, 96, 32)   18464       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 96, 96, 32)   9248        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 192, 192, 16) 2064        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 192, 192, 32) 0           conv2d_transpose_7[0][0]         \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 192, 192, 16) 4624        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 192, 192, 16) 2320        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 384, 384, 8)  520         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 384, 384, 16) 0           conv2d_transpose_8[0][0]         \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 384, 384, 8)  1160        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 384, 384, 8)  584         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 384, 384, 1)  9           conv2d_37[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 485,817\n",
      "Trainable params: 485,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(CNN_input_size) \n",
    "normalize = Lambda(lambda x : x / 255) (inputs)\n",
    "\n",
    "conv_1 = Conv2D(8, (3, 3), activation = 'elu', padding = 'same') (normalize)\n",
    "conv_1 = Conv2D(8, (3, 3), activation = 'elu', padding = 'same') (conv_1)\n",
    "pool_1 = MaxPooling2D((2, 2)) (conv_1)\n",
    "\n",
    "conv_2 = Conv2D(16, (3, 3), activation = 'elu', padding = 'same') (pool_1)\n",
    "conv_2 = Conv2D(16, (3, 3), activation = 'elu', padding = 'same') (conv_2)\n",
    "pool_2 = MaxPooling2D((2, 2)) (conv_2)\n",
    "\n",
    "conv_3 = Conv2D(32, (3, 3), activation = 'elu', padding = 'same') (pool_2)\n",
    "conv_3 = Conv2D(32, (3, 3), activation = 'elu', padding = 'same') (conv_3)\n",
    "pool_3 = MaxPooling2D((2, 2)) (conv_3)\n",
    "\n",
    "conv_4 = Conv2D(64, (3, 3), activation = 'elu', padding = 'same') (pool_3)\n",
    "conv_4 = Conv2D(64, (3, 3), activation = 'elu', padding = 'same') (conv_4)\n",
    "pool_4 = MaxPooling2D((2, 2)) (conv_4)\n",
    "\n",
    "conv_5 = Conv2D(128, (3, 3), activation = 'elu', padding = 'same') (pool_4)\n",
    "conv_5 = Conv2D(128, (3, 3), activation = 'elu', padding = 'same') (conv_5)\n",
    "\n",
    "deconv_1 = Conv2DTranspose(64, (2, 2), activation = 'elu', strides = (2, 2), padding = 'same') (conv_5)\n",
    "deconv_1 = concatenate([deconv_1, conv_4])\n",
    "\n",
    "conv_6 = Conv2D(64, (3, 3), activation = 'elu', padding = 'same') (deconv_1)\n",
    "conv_6 = Conv2D(64, (3, 3), activation = 'elu', padding = 'same') (conv_6)\n",
    "\n",
    "deconv_2 = Conv2DTranspose(32, (2, 2), activation = 'elu', strides = (2, 2), padding = 'same') (conv_6)\n",
    "deconv_2 = concatenate([deconv_2, conv_3])\n",
    "\n",
    "conv_7 = Conv2D(32, (3, 3), activation = 'elu', padding = 'same') (deconv_2)\n",
    "conv_7 = Conv2D(32, (3, 3), activation = 'elu', padding = 'same') (conv_7)\n",
    "\n",
    "deconv_3 = Conv2DTranspose(16, (2, 2), activation = 'elu', strides = (2, 2), padding = 'same') (conv_7)\n",
    "deconv_3 = concatenate([deconv_3, conv_2])\n",
    "\n",
    "conv_8 = Conv2D(16, (3, 3), activation = 'elu', padding = 'same') (deconv_3)\n",
    "conv_8 = Conv2D(16, (3, 3), activation = 'elu', padding = 'same') (conv_8)\n",
    "\n",
    "deconv_4 = Conv2DTranspose(8, (2, 2), activation = 'elu', strides = (2, 2), padding = 'same') (conv_8)\n",
    "deconv_4 = concatenate([deconv_4, conv_1])\n",
    "\n",
    "conv_9 = Conv2D(8, (3, 3), activation = 'elu', padding = 'same') (deconv_4)\n",
    "conv_9 = Conv2D(8, (3, 3), activation = 'elu', padding = 'same') (conv_9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation = 'sigmoid') (conv_9)\n",
    "model = Model(inputs = [inputs], outputs = [outputs])\n",
    "model.compile(optimizer = 'adam', loss = dice_loss_with_binary_crossentropy, metrics = [mean_IoU, 'accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint(trained_segmenter_path, monitor = 'val_loss', save_best_only = True, verbose = 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1800 samples, validate on 200 samples\n",
      "Epoch 1/25\n",
      "1800/1800 [==============================] - 158s 88ms/step - loss: 1.0185 - mean_IoU: 0.5545 - acc: 0.8778 - val_loss: 0.9906 - val_mean_IoU: 0.5978 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.99060, saving model to ../Trained/segmenter.h5\n",
      "Epoch 2/25\n",
      "1800/1800 [==============================] - 156s 87ms/step - loss: 0.9066 - mean_IoU: 0.6056 - acc: 0.8926 - val_loss: 0.8728 - val_mean_IoU: 0.6173 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.99060 to 0.87279, saving model to ../Trained/segmenter.h5\n",
      "Epoch 3/25\n",
      "1800/1800 [==============================] - 156s 87ms/step - loss: 0.8318 - mean_IoU: 0.6243 - acc: 0.9023 - val_loss: 0.7881 - val_mean_IoU: 0.6334 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.87279 to 0.78809, saving model to ../Trained/segmenter.h5\n",
      "Epoch 4/25\n",
      "1800/1800 [==============================] - 157s 87ms/step - loss: 0.7628 - mean_IoU: 0.6423 - acc: 0.9166 - val_loss: 0.7325 - val_mean_IoU: 0.6510 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.78809 to 0.73255, saving model to ../Trained/segmenter.h5\n",
      "Epoch 5/25\n",
      "1800/1800 [==============================] - 156s 87ms/step - loss: 0.6967 - mean_IoU: 0.6597 - acc: 0.9269 - val_loss: 0.6036 - val_mean_IoU: 0.6677 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.73255 to 0.60358, saving model to ../Trained/segmenter.h5\n",
      "Epoch 6/25\n",
      "1800/1800 [==============================] - 157s 87ms/step - loss: 0.5860 - mean_IoU: 0.6768 - acc: 0.9416 - val_loss: 0.5516 - val_mean_IoU: 0.6858 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.60358 to 0.55160, saving model to ../Trained/segmenter.h5\n",
      "Epoch 7/25\n",
      "1800/1800 [==============================] - 156s 87ms/step - loss: 0.5374 - mean_IoU: 0.6945 - acc: 0.9477 - val_loss: 0.5444 - val_mean_IoU: 0.7013 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.55160 to 0.54441, saving model to ../Trained/segmenter.h5\n",
      "Epoch 8/25\n",
      "1800/1800 [==============================] - 156s 87ms/step - loss: 0.5139 - mean_IoU: 0.7077 - acc: 0.9496 - val_loss: 0.5486 - val_mean_IoU: 0.7136 - val_acc: 0.9522\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/25\n",
      "1800/1800 [==============================] - 156s 87ms/step - loss: 0.4867 - mean_IoU: 0.7193 - acc: 0.9529 - val_loss: 0.4433 - val_mean_IoU: 0.7245 - val_acc: 0.9592\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.54441 to 0.44333, saving model to ../Trained/segmenter.h5\n",
      "Epoch 10/25\n",
      "1800/1800 [==============================] - 156s 87ms/step - loss: 0.4665 - mean_IoU: 0.7296 - acc: 0.9550 - val_loss: 0.4236 - val_mean_IoU: 0.7343 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.44333 to 0.42362, saving model to ../Trained/segmenter.h5\n",
      "Epoch 11/25\n",
      "1800/1800 [==============================] - 156s 87ms/step - loss: 0.4409 - mean_IoU: 0.7389 - acc: 0.9569 - val_loss: 0.5164 - val_mean_IoU: 0.7430 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/25\n",
      "1800/1800 [==============================] - 157s 87ms/step - loss: 0.4318 - mean_IoU: 0.7470 - acc: 0.9588 - val_loss: 0.4325 - val_mean_IoU: 0.7506 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/25\n",
      "1800/1800 [==============================] - 157s 87ms/step - loss: 0.4067 - mean_IoU: 0.7541 - acc: 0.9612 - val_loss: 0.4516 - val_mean_IoU: 0.7577 - val_acc: 0.9563\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/25\n",
      "1800/1800 [==============================] - 159s 88ms/step - loss: 0.4148 - mean_IoU: 0.7609 - acc: 0.9602 - val_loss: 0.4124 - val_mean_IoU: 0.7637 - val_acc: 0.9607\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.42362 to 0.41243, saving model to ../Trained/segmenter.h5\n",
      "Epoch 15/25\n",
      "1800/1800 [==============================] - 160s 89ms/step - loss: 0.3896 - mean_IoU: 0.7666 - acc: 0.9632 - val_loss: 0.4249 - val_mean_IoU: 0.7695 - val_acc: 0.9599\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/25\n",
      "1800/1800 [==============================] - 159s 89ms/step - loss: 0.3998 - mean_IoU: 0.7722 - acc: 0.9614 - val_loss: 0.4173 - val_mean_IoU: 0.7743 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/25\n",
      "1800/1800 [==============================] - 159s 89ms/step - loss: 0.4023 - mean_IoU: 0.7766 - acc: 0.9618 - val_loss: 0.3832 - val_mean_IoU: 0.7786 - val_acc: 0.9652\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.41243 to 0.38318, saving model to ../Trained/segmenter.h5\n",
      "Epoch 18/25\n",
      "1800/1800 [==============================] - 159s 89ms/step - loss: 0.3657 - mean_IoU: 0.7809 - acc: 0.9652 - val_loss: 0.3500 - val_mean_IoU: 0.7831 - val_acc: 0.9685\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.38318 to 0.34997, saving model to ../Trained/segmenter.h5\n",
      "Epoch 19/25\n",
      "1800/1800 [==============================] - 159s 89ms/step - loss: 0.3648 - mean_IoU: 0.7851 - acc: 0.9656 - val_loss: 0.3418 - val_mean_IoU: 0.7871 - val_acc: 0.9697\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.34997 to 0.34181, saving model to ../Trained/segmenter.h5\n",
      "Epoch 20/25\n",
      "1800/1800 [==============================] - 159s 88ms/step - loss: 0.3554 - mean_IoU: 0.7891 - acc: 0.9664 - val_loss: 0.3559 - val_mean_IoU: 0.7910 - val_acc: 0.9675\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/25\n",
      "1800/1800 [==============================] - 159s 88ms/step - loss: 0.3504 - mean_IoU: 0.7928 - acc: 0.9665 - val_loss: 0.3928 - val_mean_IoU: 0.7945 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/25\n",
      "1800/1800 [==============================] - 159s 88ms/step - loss: 0.3378 - mean_IoU: 0.7962 - acc: 0.9683 - val_loss: 0.3809 - val_mean_IoU: 0.7979 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/25\n",
      "1800/1800 [==============================] - 160s 89ms/step - loss: 0.3365 - mean_IoU: 0.7996 - acc: 0.9684 - val_loss: 0.3537 - val_mean_IoU: 0.8011 - val_acc: 0.9674\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/25\n",
      "1800/1800 [==============================] - 160s 89ms/step - loss: 0.3312 - mean_IoU: 0.8026 - acc: 0.9688 - val_loss: 0.3664 - val_mean_IoU: 0.8040 - val_acc: 0.9661\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/25\n",
      "1800/1800 [==============================] - 160s 89ms/step - loss: 0.3305 - mean_IoU: 0.8054 - acc: 0.9687 - val_loss: 0.3812 - val_mean_IoU: 0.8068 - val_acc: 0.9647\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1347f67f978>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_data = (X_test, Y_test),\n",
    "          batch_size = 4, verbose = 1, epochs = 25, callbacks = callbacks, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Mean_IoU = 0.807  \n",
    "## Accuracy = 0.965"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
